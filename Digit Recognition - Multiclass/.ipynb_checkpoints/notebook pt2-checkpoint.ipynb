{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0b8582-ff70-44a0-bb40-9f34a4a2a7ef",
   "metadata": {},
   "source": [
    "# About\n",
    "In this notebook, we will:\n",
    "- Test our model from last time on unseen data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf749e9-37e2-46c3-8701-d820170452ed",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b43066-d7c0-422d-9942-883df0160d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea874c9b-6eef-49fa-a8ef-182631d123c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds for reproducable results\n",
    "random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee5df0-67ee-401b-8b05-9a57698c9cf8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7656fea6-1e48-481c-8d7a-e4a715f88e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/X.npy')\n",
    "y = np.load('data/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd635e8-cd4c-494f-8d1e-0b842387dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has a shape of (5000, 400)\n",
      "y has a shape of (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X has a shape of {X.shape}')\n",
    "print(f'y has a shape of {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b10de-c0b2-4ce2-9a59-5ab2d8471bd6",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da7044e0-0c2e-47e7-b256-286342698428",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitted_model = load_model('models/Denselayer.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9469b353-e588-4a28-aeb4-3e6bbc0ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 out of 400 digits correctly predicted \n",
      "98.8% success rate\n"
     ]
    }
   ],
   "source": [
    "m,n = X.shape\n",
    "indices = np.random.randint(0,X.shape[0],400)\n",
    "num_correct_predictions = sum([np.argmax(overfitted_model.predict(X[idx].reshape(1,n), verbose=0)) for idx in indices]==y[indices].reshape(-1,))\n",
    "\n",
    "print(f'{num_correct_predictions} out of {len(indices)} digits correctly predicted \\n{num_correct_predictions/len(indices)*100:.1f}% success rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a2c38-ac2d-40a2-b029-ecd6e44f76f0",
   "metadata": {},
   "source": [
    "This model does extremely good at predicting target values for data which it trained on. It may have \"overfitted the data\". <br>Let's see what happens when we train the same model as last time but test it on a subset of data it has not seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa5d2d-1188-42e6-a3c0-9b1001fb2113",
   "metadata": {},
   "source": [
    "# Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6436d00b-1430-43a1-a4b2-c62283214309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model with the exact same weights the overfitted model started with\n",
    "model = load_model('models/Denselayer_beforetraining.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5c9b7bd-0f5a-4617-bbf9-873a206301fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need to run pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b21b3664-017e-4253-ad1d-78f3aeae588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has shape (4000, 400)\n",
      "y_train has shape (4000, 1)\n",
      "X_test has shape (1000, 400)\n",
      "y_test has shape (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# do a 80|20 training|test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "print(f'X_train has shape {X_train.shape}')\n",
    "print(f'y_train has shape {y_train.shape}')\n",
    "print(f'X_test has shape {X_test.shape}')\n",
    "print(f'y_test has shape {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52292332-17e4-4978-9881-b2f78654579e",
   "metadata": {},
   "source": [
    "We have split our data into two subsets: training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "098f3d5a-408a-4709-a8ce-20bf161656c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.0576\n",
      "Epoch 2/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0088\n",
      "Epoch 3/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5826\n",
      "Epoch 4/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4199\n",
      "Epoch 5/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3463\n",
      "Epoch 6/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3033\n",
      "Epoch 7/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2717\n",
      "Epoch 8/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2468\n",
      "Epoch 9/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2264\n",
      "Epoch 10/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2089\n",
      "Epoch 11/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1931\n",
      "Epoch 12/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1794\n",
      "Epoch 13/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1671\n",
      "Epoch 14/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1554\n",
      "Epoch 15/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1451\n",
      "Epoch 16/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1352\n",
      "Epoch 17/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1264\n",
      "Epoch 18/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1180\n",
      "Epoch 19/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1103\n",
      "Epoch 20/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1029\n"
     ]
    }
   ],
   "source": [
    "# define loss function\n",
    "model.compile(\n",
    "    loss = SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = Adam(0.001)\n",
    ")\n",
    "\n",
    "# train model\n",
    "num_epochs = 20\n",
    "history = model.fit(X_train, y_train,epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70eb5960-35a8-4d56-83d6-10b49a2498e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 out of 400 digits correctly predicted \n",
      "90.0% success rate\n"
     ]
    }
   ],
   "source": [
    "m,n = X_test.shape\n",
    "indices = np.random.randint(0,X_test.shape[0],400)\n",
    "num_correct_predictions = sum([np.argmax(model.predict(X_test[idx].reshape(1,n), verbose=0)) for idx in indices]==y_test[indices].reshape(-1,))\n",
    "\n",
    "print(f'{num_correct_predictions} out of {len(indices)} digits correctly predicted \\n{num_correct_predictions/len(indices)*100:.1f}% success rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31419e6c-d858-49bc-b47e-6c4f55b02168",
   "metadata": {},
   "source": [
    "Still convincing, but obviously not as good as the overfitted model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
