{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0b8582-ff70-44a0-bb40-9f34a4a2a7ef",
   "metadata": {},
   "source": [
    "# About\n",
    "In this notebook, we will:\n",
    "- Test our model from last time on unseen data\n",
    "- Investigate whether a convolutional neuron network can outperform the original neural network comprised of Dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf749e9-37e2-46c3-8701-d820170452ed",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b43066-d7c0-422d-9942-883df0160d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea874c9b-6eef-49fa-a8ef-182631d123c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds for reproducable results\n",
    "random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee5df0-67ee-401b-8b05-9a57698c9cf8",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7656fea6-1e48-481c-8d7a-e4a715f88e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/X.npy')\n",
    "y = np.load('data/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd635e8-cd4c-494f-8d1e-0b842387dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has a shape of (5000, 400)\n",
      "y has a shape of (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X has a shape of {X.shape}')\n",
    "print(f'y has a shape of {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b10de-c0b2-4ce2-9a59-5ab2d8471bd6",
   "metadata": {},
   "source": [
    "## Load model\n",
    "We will load the same model we trained from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7044e0-0c2e-47e7-b256-286342698428",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitted_model = load_model('models/Denselayer.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9469b353-e588-4a28-aeb4-3e6bbc0ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 out of 400 digits correctly predicted \n",
      "97.2% success rate\n"
     ]
    }
   ],
   "source": [
    "m,n = X.shape\n",
    "indices = np.random.randint(0,X.shape[0],400)\n",
    "num_correct_predictions = sum([np.argmax(overfitted_model.predict(X[idx].reshape(1,n), verbose=0)) for idx in indices]==y[indices].reshape(-1,))\n",
    "\n",
    "print(f'{num_correct_predictions} out of {len(indices)} digits correctly predicted \\n{num_correct_predictions/len(indices)*100:.1f}% success rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a2c38-ac2d-40a2-b029-ecd6e44f76f0",
   "metadata": {},
   "source": [
    "This model does extremely good at predicting target values for data which it trained on. It may have \"overfitted the data\". <br>Let's see what happens when we train the same model as last time but test it on a subset of data it has not seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa5d2d-1188-42e6-a3c0-9b1001fb2113",
   "metadata": {},
   "source": [
    "## Retrain Model\n",
    "We will load the same model, before it was trained (with randomly initialised weights), from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6436d00b-1430-43a1-a4b2-c62283214309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/Denselayer_beforetraining.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c9b7bd-0f5a-4617-bbf9-873a206301fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need to run pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21b3664-017e-4253-ad1d-78f3aeae588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has shape (4000, 400)\n",
      "y_train has shape (4000, 1)\n",
      "X_test has shape (1000, 400)\n",
      "y_test has shape (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# do a 80|20 training|test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "print(f'X_train has shape {X_train.shape}')\n",
    "print(f'y_train has shape {y_train.shape}')\n",
    "print(f'X_test has shape {X_test.shape}')\n",
    "print(f'y_test has shape {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52292332-17e4-4978-9881-b2f78654579e",
   "metadata": {},
   "source": [
    "We have split our data into two subsets: training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098f3d5a-408a-4709-a8ce-20bf161656c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0474\n",
      "Epoch 2/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9640\n",
      "Epoch 3/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5657\n",
      "Epoch 4/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4129\n",
      "Epoch 5/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3483\n",
      "Epoch 6/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3103\n",
      "Epoch 7/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2828\n",
      "Epoch 8/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2609\n",
      "Epoch 9/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2430\n",
      "Epoch 10/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2275\n",
      "Epoch 11/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2124\n",
      "Epoch 12/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1996\n",
      "Epoch 13/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1880\n",
      "Epoch 14/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1767\n",
      "Epoch 15/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1667\n",
      "Epoch 16/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1565\n",
      "Epoch 17/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1471\n",
      "Epoch 18/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1385\n",
      "Epoch 19/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1303\n",
      "Epoch 20/20\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1221\n"
     ]
    }
   ],
   "source": [
    "# define loss function\n",
    "model.compile(\n",
    "    loss = SparseCategoricalCrossentropy(from_logits = True),\n",
    "    optimizer = Adam(0.001)\n",
    ")\n",
    "\n",
    "# train model\n",
    "num_epochs = 20\n",
    "history = model.fit(X_train, y_train,epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70eb5960-35a8-4d56-83d6-10b49a2498e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 out of 400 digits correctly predicted \n",
      "92.5% success rate\n"
     ]
    }
   ],
   "source": [
    "m,n = X_test.shape\n",
    "indices = np.random.randint(0,X_test.shape[0],400)\n",
    "num_correct_predictions = sum([np.argmax(model.predict(X_test[idx].reshape(1,n), verbose=0)) for idx in indices]==y_test[indices].reshape(-1,))\n",
    "\n",
    "print(f'{num_correct_predictions} out of {len(indices)} digits correctly predicted \\n{num_correct_predictions/len(indices)*100:.1f}% success rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31419e6c-d858-49bc-b47e-6c4f55b02168",
   "metadata": {},
   "source": [
    "Still convincing, but obviously not as good as the overfitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5099f-a4e0-4aea-bcdd-99b056244aaa",
   "metadata": {},
   "source": [
    "# Convolutional Neuron Network \n",
    "A convolutional neuron network responds to inputs differently than the neural network we built from the last notebook. I found the article from Axel Thevenot has useful animations to explain: https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148\n",
    "![cnn](media/cnn.gif) <br>\n",
    "Let's break it down:\n",
    "- On the left, we have our 9×9 image, a total of 81 pixels\n",
    "- The 3×3 grid in the middle represents our neuron in the convolutional neuron network (CNN). Neurons in a CNN are often referred to as kernels\n",
    "- On the right is the kernel's output\n",
    "\n",
    "Still with me, you're doing great! Instead of consuming the entire input image in one go, as did our neurons in the Dense layer, our kernel slides over the image. Let's see what the kernel does in step 1 <br>\n",
    "## Kernel Calculation\n",
    "![cnn_step1](media/cnn_step1.jpg)<br><br>\n",
    "Those 9 pixels on the left serve as input to our kernel - each pixel is represented by a number between 0-255 (if you don't know about this, research greyscale values).<br>\n",
    "The kernel itself has 9 weights because 3×3=9.<br><br>\n",
    "![kernel](media/kernel.jpg)<br><br>\n",
    "If we perform element-wise multiplication & sum the results, we get a single number ouput.<br><br>\n",
    "![kernel](media/kernel_calculation.jpg) <br><br>\n",
    "This is the number representing the top left most pixel in the output. Repeat this calculation every time the kernel slides across."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77999c6f-2929-4654-ba78-283ca51b6e11",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "Let's assume the output of our kernel is the following 7×7 matrix <br><br>\n",
    "![kernel_output_before_activation](media/kernel_output_before_activation.jpg) <br><br>\n",
    "We are not done, each kernel has an activation function - here we will use Rectified Linear Unit (ReLU). That means anything negative turns to zero and anything else stays the same. <br> <br>\n",
    "![kernel_output_before_activation](media/kernel_output_after_activation.jpg) <br><br>\n",
    "And at long last, we have made it. This 2D matrix is the output of 1 convolutional neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061aa05-7cbb-47c9-afa0-c21cf4f08da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
